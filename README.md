# Examining LLM Bias in Whisper (small model)

## Project Overview

This project is an exploratory analysis to assess the extent to which OpenAI's automatic speech recognition (ASR) model, Whisper, relies on its large language model component over its ASR component. 

To investigate this, I calculate and compare perplexity measurements from Whisper and GPT-2, a pure language model, in response to linguistic stimuli that varies in semantic- and phonological-relatedness. If Whisper behaves similarly to a pure language model, then it should show a systematic bias towards more statistically probable transcriptions.


## Python Packages Used

- **Models**: `torch`, `whisper` (`small` model), `transformers` (`GPT2Tokenizer, `GPT2LMHeadModel`)
- **Data Manipulation:** `pandas`
- **Data Visualization:** `matplotlib.pyplot`, `seaborn` 

## Methods

### Stimuli

The stimuli used to assess this research question consists of 8 sets of 5 sentences, corresponding to each of the five experimental condition (40 sentences in total, varying in semantic- and phonological-relatedness). These sentences were generated by ChatGPT 4o. To generate the speech input, the sentences were fed into the ElevenLabs text-to-speech system (Multilingual v2 model). 

### Analysis

The audio files for each sentence is transcribed by Whisper (small) model. I then compute perplexity for both Whisper and GPT-2 for comparison.

## Results and Evaluation

GPT-2 shows a systematic negative effect of semantic relatedness on perplexity as expected (completions that are semantically-related to the most expected completion are statistically more probable than unrelated completions). Whisper, on the other hand, shows low perplexity for all sentences, regardless of experimental condition. These results suggest that it is much more likely that Whisper (small) biases towards its ASR component (as opposed to its LLM component) when transcribing speech. 

## Further directions

- Larger $n$
- More careful generation of stimuli (e.g. quantifying/standardizing measurement of semantic and phonological relatedness)
- Examining larger Whisper models
- Examining newer LLM models for more precise comparison (e.g. GPT-3, GPT-4, etc.)
- Noisy, more variable speech input

## License

[MIT License](https://opensource.org/license/mit/)
 
